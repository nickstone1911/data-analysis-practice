{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickstone1911/data-analysis-practice/blob/main/Confusion_Matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ABA Tech Lesson 08: Creating the Confusion Matrix in `scikit-learn`\n",
        "\n",
        "## Learning Objectives\n",
        "In this lesson we will:\n",
        "1. Learn the syntax for creating a confusion matrix in `scikit-learn`\n",
        "2. Customize the confusion matrix for analysis and presentation\n",
        "3. Learn how to call `classification_report` to get a nice summary of classification metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "kGBND2IIy4S8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Imports"
      ],
      "metadata": {
        "id": "N0z05Itf1W9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TqN17TW_1Vd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "KqUbCbMC1FvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee090c12-4ad3-4cbe-bb8b-fd3e0e6af341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data\n",
        "\n",
        "In this example we are going to load a popular machine learning dataset based on the historic Titanic tragedy.\n",
        "\n",
        ">- Download/move this file to your working directory: [titanic_train_clean.csv](https://docs.google.com/spreadsheets/d/13ewKdSsxu-kMTq-2IjMHwv5J-H6qbJENbPkM7MX7xL4/edit?usp=sharing)\n",
        ">- Note: this will not be a complete example of how to analyze this dataset but instead we focus on learning the syntax for the confusion matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "ItDSxz-j0XyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mydir = '/content/drive/MyDrive/BAIM4205'"
      ],
      "metadata": {
        "id": "9yylDZcQ1Mvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(mydir)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "RhwPfyiF2E_i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d7c9226-94f2-492c-9d60-72b1316c0428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/BAIM4205'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load `titanic_train_clean.csv`"
      ],
      "metadata": {
        "id": "_-kYxjzo2bHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tt = pd.read_excel('titanic_train_clean.xlsx')\n",
        "tt.head()"
      ],
      "metadata": {
        "id": "4PWOeOqS2aTp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "f563264f-7d3e-4efd-96f5-f9669486a9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'titanic_train_clean.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-471857ed8890>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titanic_train_clean.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic_train_clean.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define features and target\n",
        "\n",
        ">- The titanic problem is usually to try and predict who survived so the target is `Survived`\n",
        ">- For this tutorial we are only going to select a few features, so that we can focus on learning about the confusion matrix syntax"
      ],
      "metadata": {
        "id": "2l-Duddl21Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = tt.iloc[:, -4:]\n",
        "y = tt['Survived']\n",
        "X.head()"
      ],
      "metadata": {
        "id": "S-Xpgsmh3JmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "yrQh9kr_MsSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# End of Video 1\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kQlvFtyl8ikv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit a Basic Model"
      ],
      "metadata": {
        "id": "u5w3XZVx3oIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train_test_split()`"
      ],
      "metadata": {
        "id": "P6ceEZeS67Dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0BUHw49FLnk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 101)"
      ],
      "metadata": {
        "id": "-9_LTJIe4lAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logmodel = LogisticRegression()\n",
        "\n",
        "logmodel.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "pnSbAFDe3p9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions"
      ],
      "metadata": {
        "id": "QzPZReVo41wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = logmodel.predict(X_test)"
      ],
      "metadata": {
        "id": "4aNl2_Ne43kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate with Confusion Matrix\n",
        "\n",
        ">- Confusion Matrix: `confusion_matrix`\n",
        ">- Classification Report: `classification_report`\n",
        ">>- We can check precision, recall, f1-score using classification report\n",
        "\n",
        ">- Import statement:\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "```\n",
        "\n",
        ">- Note: the following is the default way `scikit-learn` returns a confusion matrix so we are going to be consistent with this. If you look at other documentation you may see the confusion matrix set up slightly differently:\n",
        "\n",
        "\\begin{array}{|c|c|}\n",
        "\\hline\n",
        "(TN) &  (FP) \\\\\n",
        "\\hline\n",
        "(FN) & (TP) \\\\\n",
        "\\hline\n",
        "\\end{array}\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "80uDXg8U4bwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "iIPy4SF25EM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "gBKzLKk25o4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `ravel()` from `numpy` we can flatten this array which will allow us to use multi variable assignment for tn, fp, fn, tp."
      ],
      "metadata": {
        "id": "4fDMQqJ46Fc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = cm.ravel()"
      ],
      "metadata": {
        "id": "JiRtSold6Dkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can assign values to variables for true negative (tn), false positive (fp), false negative (fn), and true positive (tp)\n",
        ">- This will help when calculating the various evaluation metrics"
      ],
      "metadata": {
        "id": "s-SMOSpo7Xrm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RiRWBUnU5xVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate a accuracy:"
      ],
      "metadata": {
        "id": "SB0xMk7S74Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (tp + tn) / (cm.sum())\n",
        "accuracy"
      ],
      "metadata": {
        "id": "c3TvQWMU55YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# End of Video 2\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "oeGSdhM582r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a DataFrame from confusion matrix\n",
        "\n",
        ">- Creating a DataFrame from the confusion matrix will allow us to perform other calculations and more easily see our results"
      ],
      "metadata": {
        "id": "20d4ID0P86JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm_df = pd.DataFrame(cm, index = ['died(0)', 'lived(1)'], columns = ['pred_died(0)', 'pred_lived(1)'])\n",
        "\n",
        "cm_df"
      ],
      "metadata": {
        "id": "NFrz5lOa5kbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a heatmap of the confusion matrix"
      ],
      "metadata": {
        "id": "uSxMs2E9BCe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(cm, annot=True, cmap = 'Blues', fmt='d')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Prediction Labels')\n",
        "plt.ylabel('Actual Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "etm2UXs_BEyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can add in new columns for row and column totals.\n",
        ">- This can help calculate other evaluation metrics"
      ],
      "metadata": {
        "id": "_aP7BMYc9i_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm_df['column_total'] = cm_df.apply(lambda x: x.sum(), axis = 1)\n",
        "\n",
        "cm_df.loc['row_total'] = cm_df.apply(lambda x: x.sum(), axis = 0)\n",
        "\n",
        "cm_df"
      ],
      "metadata": {
        "id": "w15wDnVK9sM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAQ9fryV-uBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall of the negative class (died) can be found by:\n",
        ">- Later we will find this in the classification report"
      ],
      "metadata": {
        "id": "xSy7-rDs__8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm_df['pred_died(0)']['died(0)'] / cm_df['column_total']['died(0)']"
      ],
      "metadata": {
        "id": "Z9Sor7ZP-Jfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report\n",
        "\n",
        ">- `scikit_learn` provides the `classification_report` which makes getting key classification metrics convenient."
      ],
      "metadata": {
        "id": "WWRPFGJSARNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names = ['died', 'lived']))"
      ],
      "metadata": {
        "id": "3Dyrum4MDTKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert the classification report to a DataFrame we pass in `output_dict=True` the call then DataFrame constructor"
      ],
      "metadata": {
        "id": "HOWqd0K8DK76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, y_pred, target_names = ['died', 'lived'], output_dict = True)\n",
        "\n",
        "round(pd.DataFrame(report), 2).transpose()"
      ],
      "metadata": {
        "id": "94Hl7DpaAVL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# End of Video 3\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Wo9XjLXOFIa7"
      }
    }
  ]
}